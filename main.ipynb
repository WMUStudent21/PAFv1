{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Packages and initialisations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pandas\n",
    "# %pip install scikit-learn\n",
    "# %pip install numpy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Loss Functions and M-estimators ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # MAE |y-h(x)|\n",
    "def MAE(y, y_hat):\n",
    "    return np.absolute(np.subtract(y_hat,y)).mean()\n",
    "    \n",
    "# # MSE (y-h(x))^2\n",
    "def MSE(y, y_pred):\n",
    "    # y_pred = np.dot(y_hat,theta)\n",
    "    return np.square(np.subtract(y,y_pred)).mean()\n",
    "\n",
    "''' Implement Scaling Hyperparams'''\n",
    "\n",
    "# # Huber\n",
    "def Hub(y,y_hat, n, b):     # finding optimal beta, returns ERV\n",
    "    res=y-y_hat\n",
    "    huber_lf_1 = []\n",
    "    huber_lf_2 = []\n",
    "    for j in b:\n",
    "        for i in range (n):\n",
    "            if res[i] < j:\n",
    "                huber_lf_1.append(((res[i])**2)/2)\n",
    "            else:\n",
    "                huber_lf_2.append((j*abs(res[i])) - ((j**2)/2))\n",
    "    if not huber_lf_1:\n",
    "        return np.mean(huber_lf_2)\n",
    "    elif not huber_lf_2:\n",
    "        return np.mean(huber_lf_1)\n",
    "    else:\n",
    "        if min(huber_lf_2) > min(huber_lf_1):\n",
    "            return np.mean(huber_lf_1)\n",
    "        else:\n",
    "            return np.mean(huber_lf_2)\n",
    "# # Cauchy\n",
    "def Cau(y,y_hat, n, b):      # finding optimal beta, returns ERV\n",
    "    res=y-y_hat\n",
    "    cauchy_lf = []\n",
    "    for j in b:\n",
    "        for i in range (n):\n",
    "            cauchy_lf.append((j**2) * np.log(1+((res[i]**2)/(j**2))))\n",
    "    return np.mean(cauchy_lf)\n",
    "\n",
    "\n",
    "\n",
    "### Gradient-Descent isn't a high enough improvement to be implemented. (Too computationally intensive)\n",
    "\n",
    "# def Grad_Desc_MSE(y_hat,y,theta,alpha,iters,tau_ruc):  # alpha = 0.05, iter = 5000\n",
    "#     ls = []\n",
    "#     for j in tau_ruc:\n",
    "#         y_hat = j\n",
    "#         for i in range(iters):\n",
    "#             theta = theta - (2*alpha/len(y)) * (y_hat - y[i])\n",
    "#         ls.append(theta)\n",
    "#     print(ls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the truth values\n",
    "ground_truth = pd.read_csv(\"ground_truth.csv\", usecols=['time_local', 'Total_Number_Incidents'])\n",
    "ground_truth['time_local'] = pd.to_datetime(ground_truth.time_local)\n",
    "\n",
    "# Processing train.csv\n",
    "df_3step = pd.read_csv(\"train_P.csv\", usecols=['time', 'RUC', 'kappa', 'sliding_frame'], index_col=False)\n",
    "df_3step['time'] = pd.to_datetime(df_3step.time)\n",
    "df_3step = df_3step.merge(ground_truth, how=\"left\", left_on=\"time\", right_on='time_local')\n",
    "df_3step['Total_Number_Incidents'] = df_3step['Total_Number_Incidents'].fillna(0)\n",
    "\n",
    "# Filtered data and count (.shape)\n",
    "df_3step = df_3step[(df_3step[\"sliding_frame\"] == 3) & (df_3step[\"kappa\"] == 0.25)]\n",
    "df_3step = df_3step[df_3step[\"RUC\"] != 0]\n",
    "\n",
    "# Positive (3, 0.25)\n",
    "p3s_ruc = df_3step[df_3step[\"RUC\"] > 0]\n",
    "n_p = p3s_ruc.shape[0]\n",
    "\n",
    "# Negative (3, 0.25)\n",
    "n3s_ruc = df_3step[df_3step[\"RUC\"] < 0]\n",
    "n_n = n3s_ruc.shape[0]\n",
    "\n",
    "# Export for data visualisation\n",
    "n3s_ruc.to_csv(\"merged.csv\")\n",
    "\n",
    "# Setting and splitting data for training into 60-40\n",
    "x1 = np.array(n3s_ruc[\"Total_Number_Incidents\"])\n",
    "y1 = np.array(n3s_ruc[\"RUC\"])\n",
    "x_train, x_test, y_train, y_test = train_test_split(x1, y1, test_size=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Model {Setting Parameters for beta & tau_ruc} ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# / We derive our machine learning models from, and check, its performance using the loss functions /\n",
    "# We are doing a threshold classification-type problem.\n",
    "# Residual derived from difference in predicted and true\n",
    "\n",
    "b_min = max(y1)\n",
    "b_max = min(y1)\n",
    "alpha = np.median(y1)\n",
    "b_range = np.arange(b_min,b_max,alpha)\n",
    "\n",
    "## max/min tau derived from highest/lowest RUC where accident happened\n",
    "\n",
    "# # Tau Param 1\n",
    "tau_max = min(y_train) \n",
    "tau_min = max(y_train)                                \n",
    "alph0 = np.median(y_train)\n",
    "tau_range = np.arange(tau_min,tau_max,alph0)\n",
    "\n",
    "# Tau Param 2           ## Selecting range ends based on accidents happening\n",
    "for i in x_train:\n",
    "    if i == 1:                                     \n",
    "        tau_max = min(y_train) \n",
    "        tau_min = max(y_train)                           \n",
    "alph0 = tau_min\n",
    "tau_range = np.arange(tau_min,tau_max,alph0)\n",
    "\n",
    "\n",
    "# Tau Param 3           ## Selecting tau_min based on accidents, tau_max has no preference\n",
    "for i in x_train:\n",
    "    if i == 1:\n",
    "        tau_min = max(y_train) \n",
    "tau_max = min(y_train)                          \n",
    "alph0 = np.median(y_train)/2\n",
    "tau_range = np.arange(tau_min,tau_max,alph0)\n",
    "\n",
    "# Tau Param 4           ## Selecting tau_max based on accidents, tau_min has no preference\n",
    "for i in x_train:\n",
    "    if i == 1:\n",
    "        tau_max = min(y_train) \n",
    "tau_min = max(y_train)                          \n",
    "alph0 = np.median(y_train)/2\n",
    "tau_range = np.arange(tau_min,tau_max,alph0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSE MODEL ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_MSE():\n",
    "\n",
    "    best_min = 10           ## Setting best_min and threshold to arbitrary values\n",
    "    threshold = 10\n",
    "\n",
    "    for tau_ruc in tau_range:           ## Iterate tau_range and assign best_min and threshold each time, updating\n",
    "        if (my_mse := MSE(y_train, tau_ruc)) < best_min:\n",
    "            best_min = my_mse\n",
    "            threshold = tau_ruc\n",
    "\n",
    "    y_pred = [1 if x > threshold else 0 for x in y_test]        ## Predict based on y_test and threshold\n",
    "    conf = confusion_matrix(x_test, y_pred)             \n",
    "\n",
    "    print(f\"True Negative: {conf[0][0]}, False Positive {conf[0][1]}, threshold: {threshold}\")      ## Confusion matrix for true-false\n",
    "    print(f\"False Negative: {conf[1][0]}, True Positive {conf[1][1]}, MSE: {best_min}\\n\")\n",
    "\n",
    "    score = (conf[1][1] + conf[0][0]) / len(x_test)\n",
    "\n",
    "    return best_min,threshold,score\n",
    "\n",
    "a = run_MSE()\n",
    "print (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAE MODEL ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_MAE():   \n",
    "\n",
    "    best_min = 10\n",
    "    threshold = 10\n",
    "\n",
    "    for tau_ruc in tau_range:\n",
    "\n",
    "        # scores_mae.append(MAE(y_train,tau_ruc))\n",
    "        if (my_mae := MAE(y_train, tau_ruc)) < best_min:\n",
    "            best_min = my_mae\n",
    "            threshold = tau_ruc\n",
    "\n",
    "\n",
    "    # Classify in test set\n",
    "    y_pred = [1 if x > threshold else 0 for x in y_test]\n",
    "    conf = confusion_matrix(x_test, y_pred)\n",
    "\n",
    "    print(f\"True Negative: {conf[0][0]}, False Positive {conf[0][1]}, threshold: {threshold}\")\n",
    "    print(f\"False Negative: {conf[1][0]}, True Positive {conf[1][1]}, MAE: {best_min}\\n\")\n",
    "    \n",
    "    score = (conf[1][1] + conf[0][0]) / len(x_test)\n",
    "\n",
    "    return best_min,threshold,score\n",
    "\n",
    "b = run_MAE()\n",
    "print (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HUBER MODEL ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_Hub():\n",
    "\n",
    "    best_min = 10\n",
    "    threshold = 10\n",
    "\n",
    "    for tau_ruc in tau_range:                                 # current tau is tau_ruc, against all RUC in current y_train\n",
    "\n",
    "        # scores_hub.append(Hub.one(y_train,tau_ruc, train_ix.shape[0], b_range))\n",
    "        if (my_hub := Hub(y_train, tau_ruc, y_train.shape[0], b_range)) < best_min:\n",
    "            best_min = my_hub\n",
    "            threshold = tau_ruc\n",
    "    \n",
    "    y_pred = [1 if x > threshold else 0 for x in y_test]\n",
    "    conf = confusion_matrix(x_test, y_pred)\n",
    "\n",
    "    print(f\"True Negative: {conf[0][0]}, False Positive {conf[0][1]}, threshold: {threshold}\")\n",
    "    print(f\"False Negative: {conf[1][0]}, True Positive {conf[1][1]}, Huber: {best_min}\\n\")\n",
    "    \n",
    "    score = (conf[1][1] + conf[0][0]) / len(x_test)\n",
    "\n",
    "    return best_min,threshold,score\n",
    "    \n",
    "c = run_Hub()\n",
    "print (c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CAUCHY MODEL ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_Cauc():\n",
    "\n",
    "    best_min = 10\n",
    "    threshold = 10\n",
    "\n",
    "    for tau_ruc in tau_range:                                 # current tau is tau_ruc, against all RUC in current y_train\n",
    "\n",
    "        # scores_cauc.append(Cau.one(y_train,tau_ruc, train_ix.shape[0], b_range))\n",
    "        if (my_cauc := Cau(y_train, tau_ruc, y_train.shape[0], b_range)) < best_min:\n",
    "            best_min = my_cauc\n",
    "            threshold = tau_ruc\n",
    "        \n",
    "    y_pred = [1 if x > threshold else 0 for x in y_test]\n",
    "    conf = confusion_matrix(x_test, y_pred)\n",
    "\n",
    "    print(f\"True Negative: {conf[0][0]}, False Positive {conf[0][1]}, threshold: {threshold}\")\n",
    "    print(f\"False Negative: {conf[1][0]}, True Positive {conf[1][1]}, Cauchy: {best_min}\\n\")\n",
    "    \n",
    "    score = (conf[1][1] + conf[0][0]) / len(x_test)\n",
    "\n",
    "    return best_min,threshold,score\n",
    "\n",
    "d = run_Cauc()\n",
    "print (d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ERV : Empirical Risk Value ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "erv = {a[0] : a[1], b[0] : b[1], c[0] : c[1], d[0] : d[1]}\n",
    "print(\"Best Loss Function ERV: {:.6f}, and corresponding tau: {:.6f}\".format(min(erv, key=erv.get), erv[min(erv, key=erv.get)]))\n",
    "\n",
    "scores = {\"MSE\" : a[2], \"MAE\" : b[2], \"Huber\" : c[2], \"Cauchy\" : d[2]}\n",
    "print(\"Best Model is {} with a prediction score of : {:.5f}\".format(max(scores, key=scores.get), scores[max(scores, key=scores.get)]))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40b299b9aa05c7aba1edee11e23fdf4ea17c4f193bd7a6be3fc875fc5c6ea0ab"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
